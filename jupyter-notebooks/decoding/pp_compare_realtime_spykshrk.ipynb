{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd /home/daliu/Src/spykshrk_realtime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import scipy.signal\n",
    "import holoviews as hv\n",
    "\n",
    "import warnings\n",
    "\n",
    "from spykshrk.realtime.decoder_process import PointProcessDecoder\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.util import gaussian, normal2D, apply_no_anim_boundary, simplify_pos_pandas\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPDecoder\n",
    "from spykshrk.franklab.pp_decoder.data_containers import EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                                         LinearPosition, StimLockout, Posteriors, FlatLinearPosition\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer, DecodeErrorVisualizer\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.decode_error import LinearDecodeError\n",
    "    \n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "#pd.set_option('display.width', 180)\n",
    "\n",
    " \n",
    "idx = pd.IndexSlice\n",
    "matplotlib.rcParams.update({'font.size': 28})\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from holoviews import Store\n",
    "from bokeh.models.arrow_heads import TeeHead\n",
    "Store.add_style_opts(hv.ErrorBars, ['upper_head', 'lower_head'], backend='bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load merged rec HDF store based on config\n",
    "\n",
    "config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv_300samp/bond.config.json'\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "time_bin_size = config['pp_decoder']['bin_size']\n",
    "\n",
    "# Main hdf5 data source file name\n",
    "hdf_file = os.path.join(config['files']['output_dir'],\n",
    "                        '{}.rec_merged.h5'.format(config['files']['prefix']))\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)\n",
    "\n",
    "# Open data file\n",
    "store = pd.HDFStore(hdf_file, mode='r')\n",
    "\n",
    "# Encapsulate Spike Observation panda table in container\n",
    "observ_obj = SpikeObservation.from_realtime(store['rec_3'], day=day, epoch=epoch, enc_settings=encode_settings)\n",
    "\n",
    "realtime_posteriors = Posteriors.from_realtime(store['rec_4'], day=day, epoch=epoch, \n",
    "                                               enc_settings=encode_settings)\n",
    "\n",
    "# Grab stimulation lockout times\n",
    "stim_lockout = StimLockout.from_realtime(store['rec_11'], enc_settings=encode_settings)\n",
    "\n",
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run spykshrk.realtime version of point process decoding\n",
    "observ_obj.update_observations_bins(300, inplace=True)\n",
    "\n",
    "# Create and setup online point process decoder\n",
    "pp_decoder = PointProcessDecoder(pos_range=[config['encoder']['position']['lower'],\n",
    "                                            config['encoder']['position']['upper']],\n",
    "                                 pos_bins=config['encoder']['position']['bins'],\n",
    "                                 time_bin_size=config['pp_decoder']['bin_size'],\n",
    "                                 arm_coor=config['encoder']['position']['arm_pos'],\n",
    "                                 uniform_gain=config['pp_decoder']['trans_mat_uniform_gain'])\n",
    "\n",
    "pp_decoder.select_ntrodes(config['simulator']['nspike_animal_info']['tetrodes'])\n",
    "\n",
    "observ_obj.update_observations_bins(time_bin_size)\n",
    "\n",
    "num_time_bins = observ_obj['dec_bin'].max()\n",
    "\n",
    "# Group by bin\n",
    "groups = observ_obj.groupby('dec_bin')\n",
    "\n",
    "last_bin_id = 0\n",
    "bin_timestamps = []\n",
    "spykshrk_posteriors = np.zeros([num_time_bins+1, config['encoder']['position']['bins']])\n",
    "\n",
    "for bin_id, spikes_in_bin in groups:\n",
    "    bin_timestamps.append(spikes_in_bin['dec_bin_start'].iloc[0])\n",
    "    if last_bin_id <= bin_id - 1:\n",
    "        # increment bins with no spikes\n",
    "        for bin_no_spk_id in range(last_bin_id + 1, bin_id):\n",
    "            bin_timestamps.append(bin_timestamps[-1] + time_bin_size)\n",
    "            post = pp_decoder.increment_no_spike_bin()\n",
    "            spykshrk_posteriors[bin_no_spk_id, :] = post\n",
    "        \n",
    "    # Add \n",
    "    for elec_grp_id, dec in zip(spikes_in_bin.loc[:, 'elec_grp_id'].values, \n",
    "                   spikes_in_bin.loc[:, 'x000': 'x{:03d}'.\n",
    "                                     format(config['encoder']['position']['bins']-1)].values):\n",
    "        pp_decoder.add_observation(elec_grp_id, dec)\n",
    "        \n",
    "    post = pp_decoder.increment_bin()\n",
    "    spykshrk_posteriors[bin_id, :] = post\n",
    "    last_bin_id = bin_id\n",
    "    \n",
    "spykshrk_posteriors = Posteriors.from_numpy(spykshrk_posteriors, day=day, epoch=epoch, \n",
    "                                            timestamps=np.array(bin_timestamps),\n",
    "                                            times=np.array(bin_timestamps)/30000, columns=encode_settings.pos_col_names,\n",
    "                                            encode_settings=encode_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output backend='bokeh' size=400 holomap='scrubber'\n",
    "%%opts RGB { +framewise} [height=100 width=250 colorbar=True]\n",
    "%%opts Points {+framewise} [height=100 width=250] (marker='o' size=4 alpha=0.5)\n",
    "\n",
    "\n",
    "## Plot posteriors\n",
    "\n",
    "plt_ranges = [[2461 + 250, 2461 + 400]]\n",
    "\n",
    "spyk_dec_viz = DecodeVisualizer(spykshrk_posteriors, linpos=lin_obj, \n",
    "                           enc_settings=encode_settings)\n",
    "\n",
    "realtime_dec_viz = DecodeVisualizer(realtime_posteriors, linpos=lin_obj, \n",
    "                           enc_settings=encode_settings)\n",
    "\n",
    "plt1 = spyk_dec_viz.plot_all_dynamic(stream=hv.streams.RangeXY(), plt_range=10, slide=10)\n",
    "plt2 = realtime_dec_viz.plot_all_dynamic(stream=hv.streams.RangeXY(), plt_range=10, slide=10)\n",
    "\n",
    "(plt1 + plt2).cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dec_est_pos = spykshrk_posteriors.get_distribution_view().idxmax(axis=1).apply(lambda x: int(x[1:])).to_frame()\n",
    "dec_est_pos.columns = ['est_pos']\n",
    "\n",
    "dec_est_pos = FlatLinearPosition.create_default(dec_est_pos, sampling_rate=encode_settings.sampling_rate,\n",
    "                                                arm_coord=encode_settings.arm_coordinates,\n",
    "                                                parent=spykshrk_posteriors)\n",
    "\n",
    "resamp_lin_obj = lin_obj.get_resampled(time_bin_size).get_pd_no_multiindex()\n",
    "\n",
    "error_obj = LinearDecodeError()\n",
    "\n",
    "error_table = error_obj.calc_error_table(resamp_lin_obj, dec_est_pos,\n",
    "                                         encode_settings.arm_coordinates, 2)\n",
    "\n",
    "print(error_table.loc[:, idx[:, 'abs_error']].median())\n",
    "print(error_table.loc[:, idx[:, 'abs_error']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Points {+framewise} [height=500 width=1000] (color=Cycle(values=['#FF0099', '#99FF00', '#5555FF']))\n",
    "%%opts ErrorBars {+framewise} (line_color=Cycle(values=['#FF0099', '#99FF00', '#5555FF']) alpha=0.5 line_width=1 upper_head=TeeHead(size=0) lower_head=TeeHead(size=0))\n",
    "%%output holomap='scrubber'\n",
    "#warnings.filterwarnings(action='')\n",
    "\n",
    "dec_viz = DecodeErrorVisualizer(error_table)\n",
    "\n",
    "dmap = dec_viz.plot_arms_error_dmap(20,50)\n",
    "\n",
    "dmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_error_table = error_table.loc[:, idx[:, 'abs_error']]\n",
    "abs_error_comb = (abs_error_table[('center', 'abs_error')].\n",
    "                  combine_first(abs_error_table[('left', 'abs_error')]).\n",
    "                  combine_first(abs_error_table[('right', 'abs_error')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "abs_all_error = np.abs(abs_error_comb)\n",
    "ax.hist(abs_all_error, range(200))\n",
    "ax.text(0.8, 0.6,  \"Mean error: {:.01f} cm\\nMedian error: {:.01f} cm\".format(np.mean(abs_all_error), \n",
    "                                                                             np.median(abs_all_error)),\n",
    "        transform=ax.transAxes, horizontalalignment='right', bbox={'facecolor': 'white', 'pad':20})\n",
    "plt.xlabel(\"Decode error (cm)\")\n",
    "plt.ylabel(\"Number of bins\")\n",
    "plt.xlim([0,200])\n",
    "plt.title('Decoding error with 10 ms bins and >2 cm/s', fontdict={'fontweight':'bold'})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}