{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet of code properly adds the working source root path to python's path\n",
    "# so you no longer have to install spykshrk through setuptools\n",
    "import sys, os\n",
    "root_depth = 2\n",
    "notebook_dir = globals()['_dh'][0]\n",
    "root_path = os.path.abspath(os.path.join(notebook_dir, '../'*root_depth))\n",
    "# Add to python's path\n",
    "try:\n",
    "    while True:\n",
    "        sys.path.remove(root_path)\n",
    "except ValueError:\n",
    "    # no more root paths\n",
    "    pass\n",
    "sys.path.append(root_path)\n",
    "# Alternatively set root path as current working directory\n",
    "#os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import json\n",
    "import os\n",
    "import holoviews as hv\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.data_containers import EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                              LinearPosition, StimLockout, Posteriors, FlatLinearPosition\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer, DecodeErrorVisualizer\n",
    "from spykshrk.franklab.franklab_data import FrankAnimalInfo, FrankFilenameParser, FrankDataInfo\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merged rec HDF store based on config\n",
    "\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv_30samp/bond.config.json'\n",
    "config_file = '/opt/data36/daliu/realtime/spykshrk/wang_sim_test/bond.config.json'\n",
    "\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "time_bin_size = config['pp_decoder']['bin_size']\n",
    "\n",
    "# Main hdf5 data source file name\n",
    "hdf_file = os.path.join(config['files']['output_dir'],\n",
    "                        '{}.rec_merged.h5'.format(config['files']['prefix']))\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)\n",
    "\n",
    "# Open data file\n",
    "store = pd.HDFStore(hdf_file, mode='r')\n",
    "\n",
    "# Encapsulate Spike Observation panda table in container\n",
    "observ_obj = SpikeObservation.from_realtime(store['rec_3'], day=day, epoch=epoch, enc_settings=encode_settings)\n",
    "\n",
    "realtime_posteriors = Posteriors.from_realtime(store['rec_4'], day=day, epoch=epoch, \n",
    "                                               enc_settings=encode_settings)\n",
    "\n",
    "# Grab stimulation lockout times\n",
    "stim_lockout = StimLockout.from_realtime(store['rec_11'], enc_settings=encode_settings)\n",
    "\n",
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)\n",
    "\n",
    "ripcons = nspike_data.RipplesConsData(nspike_anim)\n",
    "ripdata = ripcons.data_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = FrankAnimalInfo('/opt/data36/daliu/', 'pyBond')\n",
    "decode_info = FrankDataInfo(anim, 'decode')\n",
    "display(decode_info.entries)\n",
    "offline_posterior = decode_info.load_single_dataset_ind(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dec_viz = DecodeVisualizer(realtime_posteriors, linpos=lin_obj, riptimes=ripdata.get_above_maxthresh(5),\n",
    "                           enc_settings=encode_settings)\n",
    "\n",
    "off_dec_viz = DecodeVisualizer(offline_posterior, linpos=lin_obj, riptimes=ripdata.get_above_maxthresh(5), \n",
    "                               enc_settings=encode_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output backend='bokeh' size=400 holomap='scrubber'\n",
    "%%opts RGB { +framewise} [height=100 width=250 aspect=2]\n",
    "%%opts Points [height=100 width=250 aspect=2 ] (marker='o' color='#AAAAFF' size=2 alpha=0.7)\n",
    "%%opts Polygons (color='grey', alpha=0.5 fill_color='grey' fill_alpha=0.5)\n",
    "\n",
    "dec_viz.plot_all_dynamic(stream=hv.streams.RangeXY(), plt_range=1, slide=1, values=ripdata['starttime']-.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_posterior.memory_usage().sum()/(2**30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image {+axiswise} [height=300 width=300 aspect=1]\n",
    "%%opts Curve.arm_bound {+axiswise} [aspect=1] (line_dash='dashed' color='#AAAAAA' linestyle='--' alpha=0.5)\n",
    "%%opts Points {+axiswise} [aspect=1] (marker='*' size=18)\n",
    "%%opts NdLayout {+axiswise}\n",
    "%%output backend='matplotlib' size=200\n",
    "\n",
    "online_rip_plots = dec_viz.plot_ripple_grid(1,1)\n",
    "offline_rip_plots = off_dec_viz.plot_ripple_grid(1,1)\n",
    "\n",
    "for ii, subplot in enumerate(online_rip_plots):\n",
    "    display((subplot + offline_rip_plots[ii]).cols(2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ripple_posterior_map_error(first_posterior, second_posterior):\n",
    "\n",
    "    rip_timestamps = np.intersect1d(first_posterior.index.get_level_values('timestamp'), second_posterior.index.get_level_values('timestamp'))\n",
    "\n",
    "    first_map = []\n",
    "    second_map = []\n",
    "    for timestamp in rip_timestamps:\n",
    "        rip_first_slice = first_posterior.query('timestamp == @timestamp').get_distribution_view()\n",
    "        rip_second_slice = second_posterior.query('timestamp == @timestamp').get_distribution_view()\n",
    "        first_slice_argmax = np.argmax(rip_first_slice.values)\n",
    "        second_slice_argmax = np.argmax(rip_second_slice.values)\n",
    "        first_slice_map = encode_settings.pos_bins[first_slice_argmax]\n",
    "        second_slice_map = encode_settings.pos_bins[second_slice_argmax]\n",
    "        first_map.append(first_slice_map)\n",
    "        second_map.append(second_slice_map)\n",
    "\n",
    "    map_error = np.abs(np.array(first_map) - np.array(second_map))\n",
    "    map_error_mean = np.mean(map_error)\n",
    "    map_error_std = np.std(map_error)\n",
    "    \n",
    "    return rip_timestamps, map_error, map_error_mean, map_error_std\n",
    "\n",
    "ripple_ids = [2, 8, 18, 40, 123, 180, 199, 203, 208, 221, 235]\n",
    "\n",
    "for ripple_id in ripple_ids:\n",
    "    rt_post = realtime_posteriors.apply_time_event(ripdata.get_above_maxthresh(5))\n",
    "    off_post = offline_posterior.apply_time_event(ripdata.get_above_maxthresh(5))\n",
    "\n",
    "    rip_rt_post = rt_post.query('event_grp == @ripple_id')\n",
    "    rip_off_post = off_post.query('event_grp == @ripple_id')\n",
    "    \n",
    "    map_timestamps, map_error, map_error_mean, map_error_std = ripple_posterior_map_error(rip_rt_post, rip_off_post)\n",
    "    print('{}: mean: {:.02f} std: {:.02f}'.format(ripple_id, map_error_mean, map_error_std))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ripple_posterior_wasserstein_distance(first_posterior, second_posterior):\n",
    "\n",
    "    rip_timestamps = np.intersect1d(first_posterior.index.get_level_values('timestamp'), second_posterior.index.get_level_values('timestamp'))\n",
    "\n",
    "    was_dists = []\n",
    "    for timestamp in rip_timestamps:\n",
    "        rip_first_slice = first_posterior.query('timestamp == @timestamp').get_distribution_view()\n",
    "        rip_second_slice = second_posterior.query('timestamp == @timestamp').get_distribution_view()\n",
    "        was_dist = sp.stats.wasserstein_distance(rip_first_slice.values.squeeze(), rip_second_slice.values.squeeze()) \n",
    "        was_dists.append(was_dist)\n",
    "        \n",
    "    was_dist_mean = np.mean(was_dists)\n",
    "    was_dist_std = np.std(was_dists)\n",
    "    \n",
    "    return rip_timestamps, was_dists, was_dist_mean, was_dist_std\n",
    "\n",
    "for ripple_id in ripple_ids:\n",
    "    rt_post = realtime_posteriors.apply_time_event(ripdata.get_above_maxthresh(5))\n",
    "    off_post = offline_posterior.apply_time_event(ripdata.get_above_maxthresh(5))\n",
    "\n",
    "    rip_rt_post = rt_post.query('event_grp == @ripple_id')\n",
    "    rip_off_post = off_post.query('event_grp == @ripple_id')\n",
    "    \n",
    "    was_timestamps, was_dist, was_dist_mean, was_dist_std = ripple_posterior_wasserstein_distance(rip_rt_post, rip_off_post)\n",
    "    print('{}: mean: {:f} std: {:f}'.format(ripple_id, was_dist_mean, was_dist_std))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image {+axiswise} [height=300 width=300 aspect=1]\n",
    "%%opts Curve.arm_bound {+axiswise} [aspect=1] (line_dash='dashed' color='#AAAAAA' linestyle='--' alpha=0.5)\n",
    "%%opts Curve.was {+framewise} [apply_ranges=False]\n",
    "%%opts Points {+axiswise} [aspect=1] (marker='*' size=18)\n",
    "%%opts NdLayout {+axiswise}\n",
    "%%output backend='matplotlib' size=200\n",
    "\n",
    "def overlay(first, plot, element):\n",
    "    fig = hv.Store.renderers['matplotlib'].get_plot(first)\n",
    "    ax = plot.handles['axis']\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_yticks(fig.handles['axis'].get_yticks())\n",
    "    #ax2.set_yticklabels([t.get_text() for t in fig.handles['axis'].get_yticklabels()])\n",
    "    ax2.set_ylabel(fig.handles['axis'].get_ylabel())\n",
    "    for line in fig.handles['axis'].lines:\n",
    "        ax2.plot(*line.get_data())\n",
    "        ax2.lines[-1].set_color('k')\n",
    "        ax2.lines[-1].set_linestyle('--')\n",
    "\n",
    "def tmp(plot, element):\n",
    "    overlay(a, plot, element)\n",
    "\n",
    "for ripple_id in ripple_ids:\n",
    "    \n",
    "    rt_post = realtime_posteriors.apply_time_event(ripdata.get_above_maxthresh(5))\n",
    "    off_post = offline_posterior.apply_time_event(ripdata.get_above_maxthresh(5))\n",
    "\n",
    "    rip_rt_post = rt_post.query('event_grp == @ripple_id')\n",
    "    rip_off_post = off_post.query('event_grp == @ripple_id')\n",
    "    \n",
    "    map_timestamp, map_error, map_error_mean, map_error_std = ripple_posterior_map_error(rip_rt_post, rip_off_post)\n",
    "    \n",
    "    was_timestamp, was_dist, was_dist_mean, was_dist_std = ripple_posterior_wasserstein_distance(rip_rt_post, rip_off_post)\n",
    "    \n",
    "    error_plots = hv.Curve(map_error, group='map') + hv.Curve(was_dist, group='was')(norm=dict(framewise=True))\n",
    "    \n",
    "    display((dec_viz.plot_ripple_all(ripple_id) + off_dec_viz.plot_ripple_all(ripple_id) + error_plots).cols(2))\n",
    "\n",
    "    print('MAP: id {}: mean: {:.02f} std: {:.02f}'.format(ripple_id, map_error_mean, map_error_std))\n",
    "    print(' WASSERSTEIN: id {}: mean: {:.2e} std: {:.2e}'.format(ripple_id, was_dist_mean, was_dist_std))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}