{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet of code properly adds the working source root path to python's path\n",
    "# so you no longer have to install spykshrk through setuptools\n",
    "import sys, os\n",
    "root_depth = 2\n",
    "notebook_dir = globals()['_dh'][0]\n",
    "root_path = os.path.abspath(os.path.join(notebook_dir, '../'*root_depth))\n",
    "# Add to python's path\n",
    "try:\n",
    "    while True:\n",
    "        sys.path.remove(root_path)\n",
    "except ValueError:\n",
    "    # no more root paths\n",
    "    pass\n",
    "sys.path.append(root_path)\n",
    "# Alternatively set root path as current working directory\n",
    "#os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import json\n",
    "import os\n",
    "import scipy.signal\n",
    "import functools\n",
    "import holoviews as hv\n",
    "\n",
    "from spykshrk.util import AttrDict\n",
    "import spykshrk.franklab.filterframework_util as ff_util\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.util import gaussian, normal2D, apply_no_anim_boundary, simplify_pos_pandas, \\\n",
    "                                                normal_pdf_int_lookup\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPDecoder, OfflinePPEncoder\n",
    "from spykshrk.franklab.data_containers import DataFrameClass, EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                              LinearPosition, StimLockout, Posteriors, \\\n",
    "                                              FlatLinearPosition, SpikeWaves, SpikeFeatures, \\\n",
    "                                              pos_col_format, DayEpochTimeSeries\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer\n",
    "from spykshrk.franklab.pp_decoder.decode_error import LinearDecodeError\n",
    "\n",
    "from spykshrk.franklab.franklab_data import FrankAnimalInfo, FrankFilenameParser, FrankDataInfo\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import multiprocessing\n",
    "\n",
    "import cloudpickle\n",
    "        \n",
    "%load_ext Cython\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "hv.extension('bokeh')\n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "#pd.set_option('display.width', 80)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n",
    "hv.renderer('bokeh').theme = \"dark_minimal\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.facecolor'] = 'black'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holoviews import Store\n",
    "from bokeh.models.arrow_heads import TeeHead\n",
    "Store.add_style_opts(hv.Curve, ['linestyle'], backend='matplotlib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except:\n",
    "    print(\"No cluster or client running\")\n",
    "    \n",
    "#from dask.distributed import Client, LocalCluster\n",
    "\n",
    "#cluster = LocalCluster(n_workers=5, memory_pause_fraction=0.5)\n",
    "#client = Client(cluster)\n",
    "\n",
    "#min_worker_memory = np.inf\n",
    "#for w in cluster.workers:\n",
    "#    min_worker_memory = min(min_worker_memory, w.memory_limit)\n",
    "\n",
    "\n",
    "dask.config.set(pool=multiprocessing.pool.ThreadPool(1))\n",
    "min_worker_memory = 10e9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merged rec HDF store based on config\n",
    "\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/ripple_dec/bond.config.json'\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv/bond.config.json'\n",
    "config_file = '/home/daliu/Src/spykshrk_realtime/config/bond_single.json'\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "# Tetrode subset to use for small tests: 5, 11, 12, 14, 19\n",
    "config['simulator']['nspike_animal_info']['tetrodes'] = [1, 2, 4, 5, 7, 10, 11, 12, 13, 14, 17, 18,\n",
    "                                                         19, 20, 22, 23, 27, 29]\n",
    "#config['simulator']['nspike_animal_info']['tetrodes'] = [5, 11, 12, 14, 19]\n",
    "\n",
    "config['simulator']['nspike_animal_info']['base_dir'] = '/opt/databackup/daliu/other/mkarlsso'\n",
    "\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "time_bin_size = config['pp_decoder']['bin_size']\n",
    "\n",
    "# Change config\n",
    "sim_num = 3\n",
    "config['encoder']['position_kernel']['std'] = 1\n",
    "config['pp_decoder']['trans_mat_smoother_std'] = 2\n",
    "config['pp_decoder']['trans_mat_uniform_gain'] = 0.01\n",
    "config['encoder']['mark_kernel']['std'] = 10\n",
    "config['encoder']['spk_amp'] = 60\n",
    "config['encoder']['vel'] = 2\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "spk = nspike_data.SpkDataStream(nspike_anim)\n",
    "spk_data = SpikeWaves.from_df(spk.data, encode_settings)\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)\n",
    "linflat_obj = lin_obj.get_mapped_single_axis()\n",
    "\n",
    "ripcons = nspike_data.RipplesConsData(nspike_anim)\n",
    "ripdata = ripcons.data_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_amp = spk_data.max(axis=1)\n",
    "spk_amp = spk_amp.to_frame().pivot_table(index=['day','epoch','elec_grp_id','timestamp','time'], \n",
    "                                         columns='channel', values=0)\n",
    "spk_amp = SpikeFeatures.create_default(df=spk_amp, sampling_rate=30000)\n",
    "spk_amp_thresh = spk_amp.get_above_threshold(encode_settings.spk_amp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linflat_spkindex = linflat_obj.get_irregular_resampled(spk_amp_thresh)\n",
    "linflat_spkindex_encode_velthresh = linflat_spkindex.query('abs(linvel_flat) >= @encode_settings.vel')\n",
    "linflat_spkindex_decode_velthresh = linflat_spkindex\n",
    "   \n",
    "spk_amp_thresh_index_match = spk_amp_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_settings.vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_amp_thresh_encode = spk_amp_thresh_index_match.loc[linflat_spkindex_encode_velthresh.index.get_values()]\n",
    "#spk_amp_thresh_encode.set_index( 'elec_grp_id', append=True, inplace=True)\n",
    "#spk_amp_thresh_encode = spk_amp_thresh_encode.reorder_levels(['day', 'epoch', 'elec_grp_id' , 'timestamp', 'time'])\n",
    "spk_amp_thresh_encode.sort_index(inplace=True)\n",
    "\n",
    "spk_amp_thresh_decode = spk_amp_thresh_index_match.loc[linflat_spkindex_decode_velthresh.index.get_values()]\n",
    "#spk_amp_thresh_decode.set_index( 'elec_grp_id', append=True, inplace=True)\n",
    "#spk_amp_thresh_decode = spk_amp_thresh_decode.reorder_levels(['day', 'epoch', 'elec_grp_id' , 'timestamp', 'time'])\n",
    "spk_amp_thresh_decode.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%%prun -r -s cumulative\n",
    "\n",
    "encoder = OfflinePPEncoder(linflat=linflat_obj, enc_spk_amp=spk_amp_thresh_encode, dec_spk_amp=spk_amp_thresh_decode,\n",
    "                           encode_settings=encode_settings, decode_settings=decode_settings, chunk_size=100000\n",
    "                           #dask_worker_memory=min_worker_memory)\n",
    "                           ) \n",
    "#task = encoder.setup_encoder_dask()\n",
    "observ_obj = encoder.run_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run PP decoding algorithm\n",
    "time_bin_size = 30\n",
    "\n",
    "decoder = OfflinePPDecoder(observ_obj=observ_obj, trans_mat=encoder.trans_mat['simple'], \n",
    "                           prob_no_spike=encoder.prob_no_spike,\n",
    "                           encode_settings=encode_settings, decode_settings=decode_settings, \n",
    "                           time_bin_size=time_bin_size)\n",
    "\n",
    "posteriors = decoder.run_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "observ_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(posteriors.get_distribution_view(), axis=1)[40:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure no bins were skipped\n",
    "np.nonzero(np.invert(np.diff(posteriors.index.get_level_values('timestamp')) == 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors._to_hdf_store('/opt/data36/daliu/pyBond/analysis/bond_decode_example.h5','/analysis', \n",
    "                         'example01/bond/decode/clusterless/offline/day04/epoch01/', 'decode_sim'+str(sim_num), overwrite=True)\n",
    "ripdata._to_hdf_store('/opt/data36/daliu/pyBond/analysis/bond_decode_example.h5','/analysis', \n",
    "                      'example01/cons_ripple/day04/epoch01/', 'decode_sim'+str(sim_num), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frank_anim = FrankAnimalInfo('/opt/data36/daliu/', 'pyBond')\n",
    "data_info = FrankDataInfo(frank_anim, 'decode_example')\n",
    "display(frank_anim.data_paths)\n",
    "display(data_info.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_obj_flat_col = lin_obj.copy()\n",
    "\n",
    "new_col = []\n",
    "for entry in lin_obj_flat_col.columns:\n",
    "    if entry[0] == 'lin_dist_well':\n",
    "        new_col.append('dist_' + entry[1])\n",
    "    elif entry[0] == 'lin_vel':\n",
    "        new_col.append('vel_' + entry[1])\n",
    "    elif entry[0] == 'seg_idx':\n",
    "        new_col.append(entry[1])\n",
    "    elif len(entry[0]) > 1 and len(entry[1]) > 1:\n",
    "        new_col.append(entry[0] + '_' + entry[1])\n",
    "    else:\n",
    "        new_col.append(entry)\n",
    "\n",
    "lin_obj_flat_col.columns = new_col\n",
    "lin_obj_flat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_data._to_hdf_store('/opt/data36/daliu/pyBond/processing/bond_processing_example.h5', '/processing',\n",
    "                      'example01/bond/day04/epoch01/', 'spk_wave', overwrite=True)\n",
    "spk_amp._to_hdf_store('/opt/data36/daliu/pyBond/processing/bond_processing_example.h5', '/processing',\n",
    "                      'example01/bond/day04/epoch01/', 'spk_amp', overwrite=True)\n",
    "lin_obj_flat_col._to_hdf_store('/opt/data36/daliu/pyBond/processing/bond_processing_example.h5', '/processing',\n",
    "                      'example01/bond/day04/epoch01/', 'lin_pos', overwrite=True)\n",
    "linflat_obj._to_hdf_store('/opt/data36/daliu/pyBond/processing/bond_processing_example.h5', '/processing',\n",
    "                      'example01/bond/day04/epoch01/', 'linflat_pos', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info.save_single_data('/processing', 'example01/bond/day04/epoch01', 'spk_amp', spk_amp, overwrite=True)\n",
    "data_info.save_single_data('/processing', 'example01/bond/day04/epoch01', 'lin_pos', lin_obj, overwrite=True)\n",
    "data_info.save_single_data('/processing', 'example01/bond/day04/epoch01', 'linflat_pos', linflat_obj, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test1 = Posteriors._from_hdf_store('/opt/data36/daliu/pyBond/analysis/bond_decode.h5','/analysis',\n",
    "#                                   'decode/clusterless/offline/posterior', 'simple_trans_mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(np.nan_to_num(encoder.trans_mat['simple'], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output backend='matplotlib' size=300\n",
    "%%opts Points (s=200 marker='^' )\n",
    "%%opts Curve [aspect=3]\n",
    "%%opts Text (text_align='left')\n",
    "\n",
    "sel_distrib = observ_obj.loc[:, pos_col_format(0,encode_settings.pos_num_bins):         \n",
    "                             pos_col_format(encode_settings.pos_num_bins-1,\n",
    "                                            encode_settings.pos_num_bins)]\n",
    "    \n",
    "sel_pos = observ_obj.loc[:, 'position']\n",
    "\n",
    "max_prob = sel_distrib.max().max()/2\n",
    "\n",
    "def plot_observ(big_bin, small_bin):\n",
    "    bin_id = small_bin + 10000 * big_bin\n",
    "    spks_in_bin = sel_distrib.loc[observ_obj['dec_bin'] == bin_id, :]\n",
    "    pos_in_bin = sel_pos.loc[observ_obj['dec_bin'] == bin_id, :]\n",
    "    \n",
    "    num_spks = len(spks_in_bin)\n",
    "    plot_list = []\n",
    "    if num_spks == 0:\n",
    "        plot_list.append(hv.Curve((0,[max_prob-0.01]), \n",
    "                                   extents=(0, 0, encode_settings.pos_bins[-1], max_prob)))\n",
    "    for spk_observ, pos_observ in zip(spks_in_bin.values, pos_in_bin.values):\n",
    "        plot_list.append(hv.Curve(spk_observ, \n",
    "                                  extents=(0, 0, encode_settings.pos_bins[-1], max_prob)))\n",
    "\n",
    "        plot_list.append(hv.Points((pos_observ, [max_prob-0.01])))\n",
    "    return hv.Overlay(plot_list) * hv.Text(50,max_prob-0.05, \"num_spks: {num_spks}\\n\"\n",
    "                                           \"Timestamp: {timestamp}\\nTime: {time}\".\n",
    "                                           format(num_spks=num_spks, timestamp=time_bin_size*bin_id,\n",
    "                                                  time=time_bin_size*bin_id/30000))\n",
    "\n",
    "#Ind = Stream.define('stuff', ind=0)\n",
    "\n",
    "dmap = hv.DynamicMap(plot_observ, kdims=['big_bin', 'small_bin'], label=\"test\")\n",
    "#dmap = hv.DynamicMap(plot_observ, kdims=\n",
    "#                     [hv.Dimension('bin_id', range=(0, observ_obj['dec_bin'].iloc[-1]), step=1)])\n",
    "#dmap = hv.DynamicMap(plot_observ, kdims=\n",
    "#                     [hv.Dimension('bin_id', values=observ_obj['dec_bin'].unique())])\n",
    "\n",
    "#dmap.redim.values(bin_id=range(0, observ_obj['dec_bin'].iloc[-1]))\n",
    "dmap.redim.range(small_bin=(0, 1000), big_bin=(0, observ_obj['dec_bin'].iloc[-1]/1000 + 1))\n",
    "#dmap.redim.range(bin_id=(0, observ_obj['dec_bin'].iloc[-1]))\n",
    "#dmap.redim.values(bin_id=[4,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors.memory_usage().sum()/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output backend='bokeh' size=300 holomap='scrubber'\n",
    "%%opts RGB { +framewise} [height=100 width=350]\n",
    "%%opts Points (marker='o' color='#AAAAFF' size=1 alpha=0.05)\n",
    "%%opts Polygons (color='grey', alpha=0.3 fill_color='grey' fill_alpha=0.3)\n",
    "#%%opts Image {+framewise}\n",
    "dec_viz = DecodeVisualizer(posteriors.fillna(0), linpos=linflat_obj, riptimes=ripdata, enc_settings=encode_settings, heatmap_max=0.15)\n",
    "\n",
    "dec_viz.plot_all_dynamic(stream=hv.streams.RangeXY())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%opts NdLayout [shared_axes=False]\n",
    "%%output size=100\n",
    "\n",
    "dmap = dec_viz.plot_ripple_dynamic()\n",
    "\n",
    "plot_list = []\n",
    "plt_grp_size = 12\n",
    "plt_grps = range(math.ceil(ripdata.get_num_events()/plt_grp_size))\n",
    "plt_range_low = np.array(plt_grps) * plt_grp_size\n",
    "plt_range_high = np.append(plt_range_low[0:-1] + plt_grp_size, ripdata.get_num_events())\n",
    "\n",
    "for plt_grp, ind_low, ind_high in zip(plt_grps, plt_range_low, plt_range_high):\n",
    "    plot_list.append(hv.NdLayout(dmap[set(range(ind_low, ind_high))]).cols(3))\n",
    "\n",
    "\n",
    "#for plt_grp in plt_grps\n",
    "#hv.NdLayout(dmap[set(range(ripdata.get_num_events()))]).cols(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image {+axiswise} [height=300 width=300 aspect=3]\n",
    "%%opts Curve {+axiswise} [aspect=3] (line_dash='dashed' color='#AAAAAA' linestyle='--' alpha=0.5)\n",
    "%%opts Points {+axiswise} [aspect=3] (marker='*' size=14)\n",
    "%%opts NdLayout {+axiswise}\n",
    "%%output backend='matplotlib' size=600\n",
    "\n",
    "event_ids = ripdata.find_events([2585.42, 2791, 2938.2, 3180.2, 3263.40, 3337.4])\n",
    "plt = hv.Layout().opts(shared_axes=False)\n",
    "for id in event_ids:\n",
    "    plt += dec_viz.plot_ripple_all(id)\n",
    "\n",
    "plt.cols(1).opts(shared_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image {+axiswise} [height=300 width=300 aspect=3]\n",
    "%%opts Curve {+axiswise} [aspect=3] (line_dash='dashed' color='#AAAAAA' linestyle='--' alpha=0.5)\n",
    "%%opts Points {+axiswise} [aspect=3] (marker='*' size=14)\n",
    "%%opts NdLayout {+axiswise}\n",
    "%%output backend='matplotlib' size=600\n",
    "\n",
    "event_ids = [22, 70, 73, 99, 123, 143, 161, 174, 180, 199, 201, 229, 245]\n",
    "for id in event_ids:\n",
    "    plt += dec_viz.plot_ripple_all(id)\n",
    "\n",
    "plt.cols(1).opts(shared_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image {+axiswise} [height=300 width=300 aspect=1]\n",
    "%%opts Curve.arm_bound {+axiswise} [aspect=1] (line_dash='dashed' color='#AAAAAA' linestyle='--' alpha=0.5)\n",
    "%%opts Points {+axiswise} [aspect=1] (marker='*' size=14)\n",
    "%%opts NdLayout {+axiswise}\n",
    "%%output backend='matplotlib' size=200\n",
    "\n",
    "dec_viz.plot_ripple_all(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image {+axiswise} [height=300 width=300 aspect=1]\n",
    "%%opts Curve.arm_bound {+axiswise} [aspect=1] (line_dash='dashed' color='#AAAAAA' linestyle='--' alpha=0.5)\n",
    "%%opts Points {+axiswise} [aspect=1] (marker='*' size=18)\n",
    "%%opts NdLayout {+axiswise}\n",
    "%%output backend='matplotlib' size=200\n",
    "\n",
    "dec_viz = DecodeVisualizer(posteriors.fillna(0), linpos=linflat_obj, riptimes=ripdata.get_above_maxthresh(5), enc_settings=encode_settings)\n",
    "\n",
    "rip_plots = dec_viz.plot_ripple_grid(2)\n",
    "for plt_grp in rip_plots:\n",
    "    display(plt_grp.opts(shared_axes=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=300\n",
    "dec_viz.plot_ripple_all(242)"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}